\chapter{Constraint Sketching}\label{ch:Sketching}
Answer Set Programming (ASP) is a powerful modeling formalism for combinatorial problems. However, writing ASP models can be hard. We propose a novel method, called Sketched Answer Set Programming (SkASP), aimed at facilitating this proposal. In SkASP, the user writes partial ASP programs, in uncertain parts are left open and marked with question marks. In addition, the user provides a number of positive and negative examples of the desired program behaviour.  SkASP then synthesises a complete ASP program by  rewriting the SkASP program into another ASP program, which can then solved by traditional methods.  We evaluate our approach on 21 well known puzzles and combinatorial problems inspired by Karpâ€™s 21 NP-complete problems and on publicly available ASP encodings.

\section{Introduction}\label{sec:intro}
Many AI problems can be formulated as constraint satisfaction problems that can
be solved by state-of-the-art constraint programming (CP)  \parencite{handbookcp} or answer set programming (ASP) techniques \parencite{whatisasp}. 
Although these frameworks provide declarative representations that are in principle
easy to understand, writing models in such languages is not always easy.

%is notoriously hard to debug models written in such languages. 

On the other hand, for traditional programming languages, there has been significant attention for techniques that are able
to complete \parencite{sketching_phd_thesis} or learn a program from examples \parencite{gulwani2015inductive}. 
The idea of program sketching is to start from a sketched program and some examples
to complete the program. A sketched program is essentially a program where some of the tests and constructs
are left open because the programmer might not know what exact instruction to use.  For instance, 
when comparing two variables $X$ and $Y$, the programmer might not know whether to use $X < Y$ or $X \leq Y$ or $X > Y$ and write 
$X~{?}{=}~Y$ instead (while also specifying the domain of ${?}{=}$, that is, which concrete operators are allowed). 
By providing a few examples of desired program behaviour and a sketch, the target program can then be automatically found.
Sketching is thus a form of "lazy" programming as one does not have to fill out all details in the programs; 
it can also be considered for program synthesis although there are strong syntactic restrictions on 
the programs that can be derived; and it can be useful for repairing programs once a bug in a program has been detected.
Sketching has been used successfully in a number of applications \parencite{sketching_original,sketch_recent,jsketch} to synthesise imperative programs.
It is these capabilities that this paper brings to the field of ASP.


As a motivating example assume 
one needs to solve %a variation of a well known problem, called 
the Peacefully Coexisting Armies of Queens, a version of the $n$-queens problem with black and white queens, where queens of the same color do not attack each other. 
One might come up with the following sketched program (where 
$R_w$ ($C_b$) stand for the variable representing the row (column) of a white (black) queen): 
\begin{lstlisting}[caption=Peacefully Coexisting Armies of Queens,label=lst:queens,basicstyle=\scriptsize\ttfamily]
:- queen(w,Rw,Cw), queen(b,Rb,Cb), Rw ?= Rb.
:- queen(w,Rw,Cw), queen(b,Rb,Cb), Cw ?= Cb.
:- queen(w,Rw,Cw), queen(b,Rb,Cb), Rw ?+ Rb ?= Cw ?+ Cb.
\end{lstlisting}
This program might have been inspired by a solution written in the constraint programming language Essence available from the CSP library \parencite{csplib:prob110}.  
Intuitively, the sketched ASP specifies constraints on the relationship between two queens on the rows (first rule), columns (second rule) and diagonals (third rule), %If no solutions can be found by the ASP solver, or when some solutions found turn out to be errors, the program needs to be debugged.  A common debugging technique is commenting out constraints. In the above example, if any of the constraints 
but it expresses also uncertainty about the particular operators that should be used between the variables 
through the built-in alternatives for ${?}{=}$  (which can be instantiated to one of $=,\neq,<,>,\leq,\geq$) and for ${?}+$ (for arithmetic operations). 
When providing an adequate set of examples to the ASP, the SkASP solver will then produce the correct program.


%\luc{Again put this in a figure, left with the wrong, middle the sketch, rigth the correct program?}
%is commented out, no solution to the ASP problem exists. 
%It basically states that it is unknown whether the $\neq$ is correct in the first two rules, and whether the arithmetic operation is correct.  

The key contributions of this paper are the following: 1) we adapt the notion sketching for use with Answer Set Programming;
2) we develop an approach (using ASP itself) for computing solutions to a sketched Answer Set Program;
3) we contribute some simple complexity results on sketched ASP; 
and 4) we investigate its effectiveness and limitations on a dataset of 21 typical ASP programs. 



\input{chapters/Sketching/the_table}
\section{ASP and Sketching }\label{sec:formal}
We extend the syntax of ASP with \textit{sketched} language constructions. 
Instead of allowing atoms of the form $p(t_1, ...,t_n)$, where $p/n$ is a predicate
and the $t_i$ are terms (variables or constants), we now allow to use
{\em sketched atoms} of the form $?q(t_1, ...,t_n)$ where $?q$ is a {\em sketched predicate variable}
with an associated domain $d_q$ containing actual predicates of arity $n$. 
The meaning of the sketched atom $?q(t_1, ... ,t_n)$ is that it can be replaced
by any real atom $p(t_1, ...,t_n)$ provided that $p/n \in d_q$.
It reflects the fact that the programmer does not know which $p/n$ from $ d_q$ should be used. 
Sketched atoms can be used in the same places as any other atom. 

We also provide some syntactic sugar for some special cases and variants,
in particular, we use a {\em sketched inequality} \sketchedeq, a  {\em sketched} arithmetic operator \sketchedplus (strictly speaking, this is not a sketched predicate but an operator, but we only make this distinction where needed), and {\em sketched negation} ${?}\textit{not } p(X)$.  The domain of \sketchedeq is the set $\{=,\neq,<,>,\geq,\leq,\top\}$, where $\top$ is the atom that is always satisfied by its arguments, the domain of \sketchedplus is the set $\{ +, -, \times, \div, \dist \}$ where $\dist(a,b)$ is defined as $| a - b |$, and the domain of ${?}\textit{not}$  is $\{\emptyset, not\}$. An example of sketched inequality can be seen in Line 3 of Figure \ref{lst:sudoku}, examples of sketched predicates and negation in Line 4 of Figure \ref{lst:ham} and sketched arithmetic in Line 5 of Figure \ref{lst:queens}.


\textit{A sketched variable} is a sketched predicate, a sketched negation, a sketched inequality or a sketched arithmetic operator. The set of all sketched variables is referred as $S$. 
Predicate $p$ \textit{directly positively (negatively) depends} on $q$ iff $q$ occurs positively (negatively) in the body of a rule with $p$ in the head or $p$ is a sketched predicate and $q$ is in its domain; $p$ {\em depends on} $q$ iff $q$ is in the transitive closure of predicates on which $p$ directly depends. A sketch is \textit{stratified} iff there is no negative cyclic dependency. We restrict programs the stratified case.
An \textit{example} is a set of ground atoms. 

A \textit{preference} is a function from $S$ to $\mathbb{Z}$. A substitution $\theta$ is \textit{preferred} over $\theta'$ given preferences $f$ iff for all $s_i \mapsto d_i \in \theta$ and $s_{i} \mapsto d_{i}' \in \theta'$ it holds that $f(d_i) \geq f(d_{i}')$ and at least one inequality is strict. First, when $f(\theta)$ is constant,
all substitutions are equal and there are no preferences. Because specifying preferences might impose an extra burden on the user, we also provide default preferences for the built-in sketched variables (like inequality, etc), cf. the experimental section.



\begin{definition}[Sketched Answer Set Problem (SkASP)]
  Given  a sketched answer set program $P$ with sketched variables $S$ of domain $D$ and preferences $f$, and positive and negative sets of examples \eplus and \eminus, the \emph{Sketched Answer Set Problem} is to find all substitutions $\theta:S\mapsto D$ preferred by $f$ such that $P\theta \cup e$ has an answer for all $e$ in \eplus and for no $e$ in \eminus. 
%
The decision version 
%\emph{SkASP-dec} 
of SkASP  asks whether there exists such a substitution $\theta$.
\end{definition}
%E.g., Figure \ref{lst:ham} represents a sketch of Hamiltonian Cycle. %with $P$ being the rules in Lines \ref{line:reached}, \ref{line:reached2}, \ref{line:ham_constraint} and $S{=}\{ {?}p, {?}q, {?}\textit{not} \}$, $D {=} \{ \{\textit{reached/1}, \textit{node/1} \}_p, \{\textit{reached/1}, \textit{node/1} \}_q, \{\emptyset, \textit{not} \}_{\textit{not}} \}$, \\$\eplus {=} \{\{ \textit{cycle}(a,b),\textit{cycle}(b,c),\textit{cycle}(c,a)\} \}$, $\eminus  {=} \{ \{ \textit{cycle}(a,b),\textit{cycle}(b,a) \} \}$ and $f\equiv 1$. 


\section{Rewriting Schema}\label{sec:method}
%\textbf{Combinatorial explosion.} 
One might consider a baseline approach that would enumerate all instances of the ASP sketch, and in this way produce
one ASP program for each assignment that could then be tested on the examples. 
This naive grounding and testing approach is, however, infeasible: the number of possible combinations grows exponentially with the number of sketched variables. E.g., for the Radio Frequency Problem there are around $10^5$ possible assignments to the sketched variables. Multiplied by the number of examples, around a million ASP programs would have to be generated and tested. This is  infeasible in practice.   



The key idea behind our approach is to rewrite a SkASP problem $(P,S,D,f,\eplus,\eminus)$ into an ASP program such that the original sketching program has a solution iff the ASP program has an answer set. 
This is achieved by 1) inserting \textit{decision variables} into the sketched predicates,
and 2) introducing {\em example identifiers} in the predicates. 

The original SkASP problem is then turned into an ASP problem  
on these decision variables and solutions to the ASP problem allow to reconstruct the SkASP substitution.


The rewriting procedure has four major steps: \textit{example expansion}, \textit{substitution generation}, \textit{predicate reification} and \textit{constraint splitting}. (Here we follow the notation on meta-ASP already used in the literature \parencite{inductive_asp,asp_meta}.) 

\vspace{3pt}
\textbf{Example Identifiers} 
To allow the use of multiple examples in the program, every relevant predicate is extended with
an extra argument that represents the example identifier.  The following steps are used
to accommodate this in the program,denoted as \metae.
% \skadded{more formal} a) each ground atom $e(\bar x)$ in the set $E^+$ and $E^-$ is rewritten as two facts $e(i_e,\bar x)$ and \textit{positive($i_e$)} (\textit{negative($i_e$)} respectively), where $i_e$ is the index of the example, e.g. in the Hamiltonian path Listing \ref{lst:ham} the first positive example becomes \textit{positive(1). cycle(1,a,b). cycle(1,b,c). cycle(1,c,a).}, similarly for the negative one. b) All predicates in $P$ that transitively depend on the predicates in examples get a fresh variable $E$ as the first argument, e.g., in the same listing the predicate \textit{reached/1} depends on the example but \textit{node} does not. All rules with expanded predicates get $\textit{examples}(E)$ as a guard in the body c) All facts, that predicates depend transitively on the examples, get an extra argument $e_i$, with all values of positive and negative indices, in the same listing we see that the predicate node does not depend on the examples and the facts are not expanded. The first rule in Listing \ref{lst:ham} becomes:
\begin{enumerate}
\item
  Let $\textit{SP}$ be the set of all predicates that depend on a predicate occurring in one of the examples. 
\item
  Replace each literal $p(t_1, ...,t_n)$ for a predicate $p \in \textit{SP}$ in the program $P$ by 
the literal $p(E,t_1, ...,t_n)$, where $E$ is a variable not occurring in the program. 
\item
  Add the guard $\textit{examples}(E)$ to the body of each rule in $P$.\
\item
For each atom $p(t_1,...,t_n)$ in the $i$-th example, add the fact $p(i,t_1,...,t_n)$ to $P$.
\item
  For each positive example $i$, add the fact $\textit{positive}(i)$ to $P$, and for each negative one, the fact $\textit{negative}(i)$.
\end{enumerate}
E.g., the rule in Line \ref{line:reached} of Figure \ref{lst:ham} becomes Line \ref{line:reach_rewritten} of Figure \ref{lst:rewriting}, and the example in Line \ref{line:example} is rewritten as in Line \ref{line:example_rewritten}.



%\paragraph{Example Expansion} \skadded{more formal} a) each ground atom $e(\bar x)$ in the set $E^+$ and $E^-$ is rewritten as two facts $e(i_e,\bar x)$ and \textit{positive($i_e$)} (\textit{negative($i_e$)} respectively), where $i_e$ is the index of the example, e.g. in the Hamiltonian path Listing \ref{lst:ham} the first positive example becomes \textit{positive(1). cycle(1,a,b). cycle(1,b,c). cycle(1,c,a).}, similarly for the negative one. b) All predicates in $P$ that transitively depend on the predicates in examples get a fresh variable $E$ as the first argument, e.g., in the same listing the predicate \textit{reached/1} depends on the example but \textit{node} does not. All rules with expanded predicates get $\textit{examples}(E)$ as a guard in the body c) All facts, that predicates depend transitively on the examples, get an extra argument $e_i$, with all values of positive and negative indices, in the same listing we see that the predicate node does not depend on the examples and the facts are not expanded. The first rule in Listing \ref{lst:ham} becomes: \begin{equation*} \textit{reached}(E,Y) \leftarrow \textit{cycle}(E,a,Y),\textit{examples}(E).  \end{equation*}

\vspace{3pt}
\textbf{Substitution Generation} 
We now introduce the decision variables, referred as \metad:
\begin{enumerate}
\item
For each sketched variable $s_i$ with domain $d_i$ 
$$1~\{ \textit{decision}\_s_i(X) : d_i(X) \}~1 .$$ 
\item 
For each value $v$ in $d_i$, add the fact $d_i(v)$.
\end{enumerate}
This constraint ensures that each answer set has exactly one value from the domain assigned
to each sketched variable. %, its subset one and only one decision per each sketched variable. 
This results in a one-to-one mapping between decision atoms and sketching substitution $\theta$. An example can be see in Lines \ref{line:decision1} and \ref{line:decision2} of Figure \ref{lst:rewriting}.

% in the Listing \ref{lst:ham} the first constraint generated would be \begin{equation*} 1~\{~\textit{decision\_p}(X)~:~\textit{domain\_p}(X)~\}~1.  \end{equation*}

\vspace{3pt}
\textbf{Predicate Reification} 
We now introduce the reified predicates, referred as \metar
\begin{enumerate}
\item
Replace each occurrence of a sketched atom $s(t_1,...,t_n)$ in a rule of $P$ with the atom $\reified\_s( D, t_1, \dots, t_n)$, 
and add $\textit{decision}\_s(D)$ to the body of the rule.
\item
For each sketched variable $s$ and value $d_i$ in its domain, add the following rule to $P$: %d$\skadded{domains and types are unexplainded}
%\begin{equation*}
%  \begin{aligned}
$$\reified\_s(d_i,X_1, \dots, X_n) \leftarrow d_i(X_1, \dots, X_n).$$
    % \cdots \\ \reified\_s(E,"d_k",X_1, \dots, X_n) &\leftarrow d_k(E,X_1, \dots, X_n).  \end{aligned} \end{equation*}
where the first argument is the decision variable for $s$.
 %and ``$d_i$'' in the reified predicate is the decision variable. 
\end{enumerate}
Thus, semantically $\reified\_s(d_i,X_1, \dots, X_n)$ is equivalent to $d_i(X_1, \dots, X_n)$  
and $\textit{decision}\_s(d_i)$ indicates that the predicate $d_i$ has been selected for the sketched variable $s$.
% In Listing \ref{lst:queens}, we would reify equality as: \begin{equation*} \begin{aligned} &eq("{=}" , X, Y)    \leftarrow X =  Y, \domaineq(X), \domaineq(Y).\\ &eq("{\leq}", X, Y)  \leftarrow X \leq Y, \domaineq(X), \domaineq(Y).\\ & \dots \\ &eq("\top", X, Y) \leftarrow \domaineq(X), \domaineq(Y).  \end{aligned} \end{equation*}
Notice that we focused here on the general case of a sketched predicate ${?}p(\dots)$. 
It is straightforward to adapt this for 
the sketched inequality, negation and arithmetic. Examples of reification can be seen in Lines \ref{line:reified_q} of Figure \ref{lst:rewriting} for the sketched ${?}q$ of the sketch in Figure \ref{lst:ham} and in Lines \ref{line:reified_not1}, \ref{line:reified_not2} for reified negation.

\vspace{3pt}
\textbf{Integrity Constraint Splitting} 
(referred as \metac)
\begin{enumerate}
  \item Replace each integrity constraint $\leftarrow \textit{body}$ by: 
$$\leftarrow \textit{body}, \textit{positive}(E) $$
$$\textit{negsat}(E) \leftarrow \textit{body}, \textit{negative}(E) $$
\item
And add the rule to the program:
$$ \leftarrow \textit{negative}(E), \textit{not} ~ \textit{negsat}(E).$$ 
\end{enumerate}
This will ensure that all positives and none of the negatives have a solution. For example, the constraint in Line \ref{line:ham_constraint} of Figure \ref{lst:ham} is rewritten into a positive constraint in Lines \ref{line:positive_rewritten1}, \ref{line:positive_rewritten2} and into a negative in Lines \ref{line:negative_rewritten1}, \ref{line:negative_rewritten2}.


Another important result is that the preferences do not affect the decision complexity. Proofs can be found in the supplementary materials. 
\begin{theorem}[Sound and Complete Sketched Rewriting]
  A sketched ASP program $(P, S, D, f, \eplus,\eminus)$ has a satisfying substitution $\theta$ iff \skadded{the meta program $T=$ \mbox{$\metae\cup\metad \cup \metar \cup \metac$} has an answer set.}
  \label{theorem:rewriting}
\end{theorem}
Interestingly, the sketched ASP problem has the same complexity as the original ASP program.
\begin{theorem}[Complexity of Sketched Answer Set Problem]
  The decision version of SkASP is NP-complete.
  \label{theorem:complexity_sat}
\end{theorem}
\begin{proof} \emph{Membership.}
Follows from the encoding of SkASP into a fragment of ASP which is in NP. 

\emph{Completeness.}
Let $P'$ be an arbitrary answer set program, then the question of whether it has an AS is reduced to asking if an empty $\theta$ satisfies the following SkASP: consider $S = \emptyset, \eminus = \emptyset,\eplus = \{ \emptyset \},f\equiv1$ and $P=P'$. If $\theta$ satisfies the SkASP, then $P$ and consequently $P'$ have an answer set.
\end{proof}
\textbf{Dealing with preferences} 
Preferences are, as we shall show in our experiments, useful to restrict the number of solutions.
We have implemented preferences using a post-processing approach (which will also allow to apply the schema to other formalisms such as CP or IDP \parencite{idp}).
We first generate the set of all solutions $O$ (without taking into account the preferences), and then post-process $O$. Basically, we filter out
from $O$ any solution that is not preferred (using tests on pairs $(o,o')$ from $O \times O$). %and filter out using the set $N$ to filter out not preferred substitutions.
The preferences introduce a partial order on the solutions. 
\skadded{Assume ${?}p$ (${?}q$) can take value  $p_1$ ($q_1$) with preference of $1$ and $p_2$ ($q_2$) with $2$. If $(p_1,q_2)$ and $(p_2,q_1)$ are the only solutions, they are kept because they are incomparable ($(1,2)$ is not dominated by $(2,1)$ (and vice versa). If $(p_1,q_1)$ is also solution, 
$(p_1,q_2)$ and $(p_2,q_1)$ are removed because they are dominated by $(p_1,q_1)$. }
%In future work, we plan to make the search more effective by using the preferences
%in the search process (using ASP extensions \parencite{asprin}) or by formulating the SkASP task as an optimisation problem (using built-in 
%ASP constructs).

%While preferences do not affect the decision version SkASP, they have a great practical value. We propose a simple method how to post-process the solutions $O$, by an optimized version of comparing pairs of solutions $(o,o')$ in $O\times O$. We create a set of non-dominating solutions $N$ and then iterate over pairs $(o,o')$, using the set $N$ to filter out not preferred substitutions. Note, the preferences introduce a partial order on the solutions.

\section{System Extension: Aggregates and Use-Case}
\skadded{An aggregate} \textit{\#agg} \skadded{is a function from a set of tuples to an integer. For example,} $\#\textit{count}\{ C,R: \textit{queen}(C,R) \} $ \skadded{counts the number of queens. Aggregates are often useful for modeling. 
However, adding aggregates to non-disjunctive ASP raises the complexity of an AS existence check, unless aggregate dependencies are stratified \parencite{aggregates_complexity}. It is possible to add aggregates into our system under the following restrictions: stratified case, aggregates occur in the body in the form ${N = \#\textit{agg}\{ \dots \}}$, sketched with the keyword} \verb|?#| \skadded{, where} \textit{\#agg} \skadded{can be \textit{max}, \textit{min}, \textit{count} and \textit{sum}. This immediately allows us  to model problems such as Equal Subset Sum (for details, see the repository), where we essentially sketch the constraint: }
\begin{Verbatim}[fontsize=\footnotesize,xleftmargin=0mm]
:-S1 != S2,S1 = ?#{V,X:val(X,V),subset1(X)}..
\end{Verbatim}

\skadded{More formally, each aggregate we consider can be seen as an expression of the form:}
\begin{equation*}
  S = \#\textit{agg}\{ Z_1,\dots,Z_n: \textit{cond}(\overbrace{X_1,\dots,X_k}^{\textit{internal}}, \overbrace{Y_1,\dots,Y_h}^{\textit{external}},\overbrace{Z_1,\dots,Z_n)}^{\textit{aggregated}} \}\end{equation*}
\skadded{where $S$ is an integer output, and $Y_1,\dots,Y_k$, shortened as $\bar Y$ are bound to other atoms in the rule, to which we refer as \textit{external($\bar Y$)}. Then, a sketched aggregate $?\#$, can be reified similarly to the regular sketched atoms, i.e.:}
\begin{equation*}
  \textit{reifed}(S,sum,\bar Y) \leftarrow S = \#\textit{sum} \{ \bar Z : \textit{cond}(\bar X, \bar Y, \bar Z) \}, \textit{external}(\bar Y).
\end{equation*}
similarly for other aggregate functions; the same rules, e.g., the example extension, apply to aggregate reification.


\skadded{With aggregates we can sketch a significantly larger class of problems. Consider the problem from the Functional Pearls Collection: ``Finding celebrities problem'' \parencite{celebrity_problem} \footnote {\scriptsize ASP code:~ \url{hakank.org/answer_set_programming/finding_celebrities.lp4}}. Problem statement: ``Given a list of people at a party and for each person the list of people they know at the party, we want to find the celebrities at the party.
A celebrity is a person that everybody at the party knows but that only knows other celebrities. At least one celebrity is present at the party.'' The sketch core looks as follows (names are shortened):}
\begin{Verbatim}[fontsize=\small]
n(N) :- N = ?#{ P : p(P) }.
:- c(C), p(C), n(N), S = ?#{P : k(P,C), p(P)}, S < N-1.
:- c(C), p(C), not c(P), k(C,P).
\end{Verbatim} 


\section{Experimental Evaluation}\label{sec:experiments} 




For the experimental evaluation we have created a dataset consisting 
of 21 classical combinatorial problems among which most are NP-complete. 
Our dataset contains Graph Clique; 3D Matching; Vertex and Edge Coloring; Vertex and Edge Domination; Exact, Vertex and Clique Covers; Sudoku; Latin Square; B\&W and n-Queens; Hitting Set; Hamiltonian Cycle; Feedback Vertex and Arc Sets; Radio Frequency Assignment (FAP); Set Packing and Splitting; Subgraph Isomorphism. For more detailed dataset description we refer to the supplementary material.

All problems, their code, and implementation details, can be found in the accompanying Github repository:\\
{\small\url{https://github.com/SergeyParamonov/sketching}}
%\paragraph{Examples.} For the experiments measuring the number of solutions, we use the manually created examples that are provided in the Github repository for each sketch. For the experiment in Figure \ref{fig:latin_square_random} we generated random positive and negative examples using the ASP encoding. Since, for all problems stochastic decisions have to be made (such as picking $2$ positive examples out of $7$), the result are averaged over $20$ runs for each experiment.

\textbf{Dataset of Sketches.}
The key challenge in evaluating program synthesis techniques such as SkASP is the absence of 
benchmark datasets (as available in more typical machine learning tasks). At the same time,
although there are many example ASP programs available in blogs, books or come with software,
these typically employ advanced features (such as incremental grounding, optimization or external sources) which are not supported by SkASP as yet.
Therefore we had to design our own dataset in a systematic way (and put it in the public domain).
The dataset is based on a systematic concept (the 21 problems by Karp). When 
we could find encodings for these problem (such as Sudoku in Figure \ref{lst:sudoku} from \parencite{asp_tutorial_sudoku} and Hamiltonian Cycle in Figure \ref{lst:ham} from \parencite{ASPbook}) we took these problems, in all other cases we developed a solution according to the standard generate and test development methodology of ASP.
Specifically of \qfive we looked for different encodings in the public domain of ASPâ€™s favorite -- the N-queens problem (these encoding can tacle even its NP-complete version \parencite{complexity_nqueens}).

After creating all the ASP programs, we turned them into sketched ASP programs by looking for meaningful opportunities to use 
sketched variables. We introduced sketched variables to replace operators (such as equalities and inequalities), to replace arithmetic (such as plus and minus)
and to decide whether to use negated literals or not, and to make abstraction of predicates for which another predicate existed with the same signature.

Finally, we had to select the examples in a meaningful way, that is, we selected examples that would be informative
(as a user of SkASP would also do). Positive examples were actually selected more or less random,
negative examples are meant to violate one or more of the properties of the problem. Furthermore, we also 
tried to select examples that carry different information (again as a user of SkASP would do). We selected between 4 and 7 examples for each model. Where relevant in the experiments, we sampled the sketched variables (e.g. \qfive) or the examples (e.g. \qthree)


%\paragraph{Time taken} All sketching problems in the dataset, which are mentioned in this section, are solved by our method within a few seconds. This is sufficient in practice, which explains why we do not provide further details of the running time for our method.

\textbf{Experimental questions} \skadded{ are designed to evaluate how usable is SkASP in practice. 
  Users want in general to provide only a few examples (\qone-\qthree), to obtain a small number of solutions (ideally only one) (\qone-\qtwo), the examples should be small (\qfour), the solutions should be correct (all), want to know whether and when to use preferences (\qtwo), and how robust the technique is to changes in the encoding (\qfive) as it is well known in ASP that small changes in the encoding can have large effects. Finally, they are typically interested in how the learned programs change as the sketches becomes more complex (\qthree).
With this in mind,} we have designed and investigated the following experimental questions:
\begin{itemize}
\item \qone: What is the relationship between the number of examples and the number of solutions? How many examples does it take to converge?
\item \qtwo: Are preferences useful?
\item \qthree: What is the effect of the number of sketched variables on the convergence \skadded{and correctness of the learned programs}?
\item \skadded{\qfour: Do models learned on examples with small parameter values generalize to models with larger parameter values?}
\item \skadded{\qfive: What is the effect of encoding variations on the number of solutions and their correctness? }
\end{itemize}


\textbf{Implementation details and limitations.} The SkASP engine is written in Python 3.4 and requires pyasp. All examples have been run on a 64-bit Ubuntu 14.04, tested in Clingo 5.2.0. The current implementation does not support certain language constructs such as choice rules or optimization. 


We use the \textit{default preferences} in the experiments for the built-in inequality sketch \sketchedeq: namely $=$ and $\neq$ have equal maximal preference. A user can redefine the preferences by giving them weights. Our experiments indicate that for other sketched types no default preferences are needed.



\begin{figure*}[tb]
  \centering
  \begin{subfigure}[t]{0.325\textwidth}
   \includegraphics[width=\scalefigures\textwidth]{convergence_without_preferences.png}
   \caption{Convergence without preferences (with 5 sketched variables): B\&W Queens (Sketch \ref{lst:queens}) and FAP converge, while Sudoku does not}
    \label{fig:convergence_without_preferences}
  \end{subfigure}
 \hfill
 \begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\textwidth]{average_number_of_solutions.png}
  \caption{Average number of solutions over the dataset, split into the \textit{easy} group converging without preferences and \textit{hard} not converging }
  \label{fig:preferences_effect}
  \end{subfigure}
\hfill
\begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\textwidth]{number_of_solutions_all.png}
  \caption{Between 2 and 7 examples are needed to obtain a unique solution (or a small group of equivalent ones) under preferences.}
  \label{fig:number_of_solutions}
  \end{subfigure}
  \caption{\qone and \qtwo: convergence without preferences (left), across the dataset (middle), for each problem (right); log-scale}%; converging on the 2nd example are not depicted); log-scale; the number of sketched indicated in parentheses}
\end{figure*}



We investigate \qone by measuring the impact of the number of examples 
on the number of solutions of the 21 SkASP problems. 
An interesting observation is that even if the user wants to 
solve, say the Latin Square $20\times 20$, she does not need to provide 
examples of size $20\cdot 20= 400$. She can simply provide $3\times 3$ examples 
and our SkASP problem will learn the generic 
Latin Square program (see Figure \ref{lst:latin_square}). 

Figure \ref{fig:convergence_without_preferences} shows how the number of solutions 
for some of our 21 SkASP problems depends on the number of examples. 
In some cases, 7 examples are sufficient 
to converge to a single solution e.g., FAP, B\&W Queens. 
%

On some other problems, however, after 7 examples there still remain 
many solutions (on average 18 for problems that do not converge). 
Figure \ref{fig:preferences_effect} reports the same information as Figure \ref{fig:convergence_without_preferences} for all 21 problems: the average number of solutions; the average on the 9 that 
converge within 7 examples, referred to as the \textit{easy problems}; and the average on the 12 that still have several 
solutions after 7 examples, referred to as the \textit{hard problems}. 
When SkASP  does not converge to a unique solution, this leaves 
the user with choices, often amongst equivalent ASP programs, which is undesirable.  

For problems that do not converge after a few examples, we propose to 
use preferences, as provided by our SkASP framework. 
We use the default preference described earlier. 

\begin{figure*}[tb]
  \centering
\begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\textwidth]{fap_different_number_of_vars.png}
  \caption{The effect of the number of sketched variables on the solutions with preferences}
  \label{fig:fap_with_preferences}
  \end{subfigure}
    \hfill
\begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\linewidth]{fap_with_preferences.png}
  \caption{The effect of the number of sketched variables on the solutions without preferences}
  \label{fig:fap_without_preferences}
  \end{subfigure}
  \hfill
\begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\linewidth]{precision_n_queens.png}
  \caption{\skadded{Dependency between the number of sketched variables and precision}}
  \label{fig:precision_n_queens}
  \end{subfigure}
  \caption{\qthree: the effect of different number of sketched variable, FAP (left, middle; log-scale); $N$-queens (right)}
  \label{fig:second_row}
\end{figure*}


We investigate \qtwo by  measuring again the impact of the number of examples 
on the number of solutions. 
In Figure \ref{fig:number_of_solutions}, we observe that all problems 
have converged in less than 7 examples (under default preferences). 
The impact of preferences on the speed 
of convergence is even more visible on the whole set of problems, as reported in 
Figure \ref{fig:preferences_effect}. 
The number of solutions with preferences is smaller, and often much smaller 
than without preferences, whatever the  
number of examples provided. 
With preferences, all our 21 problems are learned with 7 examples.  



To analyze the number of solutions in \qthree, we look into the convergence of FAP  
by varying the number of sketched variables. The original 
sketched program of FAP contains 5 sketched variables. 
We vary it from 2 to 5 by turning 3, 2, 1, or 0 sketched variables into 
their actual value (chosen randomly and repeated over multiple runs). As expected, in Figure \ref{fig:fap_with_preferences}, we observe that 
the more there are sketched variables in the SkASP, the slower the number 
of solutions decreases. Furthermore, the number of sketched variables has a greater impact on the convergence without preferences, as we see in Figure \ref{fig:fap_without_preferences}. After 3-5 examples under preferences we have fewer than 10 solutions, while without preferences there are still dozens or hundreds of solutions.

\skadded{To analyze \textit{correctness} in \qthree, we need first to define it. Informally, we mean that the program classifies arbitrary examples correctly, i.e., positive as positive, etc. A typical metric to measure this is \textit{accuracy}. However, there are no well defined arbitrary positive and negative examples for the most problems: what is an arbitrary random example for Feedback Arc Cover? Problems like Sudoku and $N$-queens do have standard examples because they are parameterized with a single parameter, which has a default value. Furthermore, for the standard $8$-queens we know all solutions analytically, i.e., 92 combinations. Another issue is that the negative and positive classes are unbalanced. The usual way to address this issue is to use \textit{precision}, i.e., $\frac{\text{True Positive}}{\text{True+False Positives}}$. (Recall is typically one because the incorrect programs produce way too many solutions that include the correct ones.) In Figure \ref{fig:precision_n_queens}, we see that in all cases we were able to reach the correct solution (here the locations of sketched variables were fixed as specified in the dataset); while increasing the number of sketched variables generally decreases the precision.} % and as Figure \ref{fig:systematic_precision} if we place them differently extra examples might be required to reach the correct solution, even for the same number of sketched variables.

\skadded{To investigate \qfour, we have used the Latin Square from Listing \ref{lst:latin_square}. We have used examples for Latin Square $3\times 3$, and verified its correctness on Latin Square $4 \times 4$ (which can be checked analytically because  all solutions are known). We have discovered, that there is an inverse dependency between number of solutions and accuracy, see Figure \ref{fig:latin_square_generalization}. This happens because there are typically very few useful or ``intended'' programs while there are lot of incorrect ones.}


To investigate \qfive, we have focused on the $N$-queens problem and collected several encodings from multiple sources: Potascco, Hakank.org, an ASP course by Tran Cao Son\footnote{{\url{www.hakank.org/answer_set_programming/nqueens.lp}\\\url{www.cs.uni-potsdam.de/~torsten/Lehre/ASP/Folien/asp-handout.pdf}\\\url{www.cs.nmsu.edu/~tson/tutorials/asp-tutorial.pdf}}} and our encoding. 
Whereas all the encodings model the same problem they show significant variations 
in  expressing constraints. To reduce the bias in how the sketched variables are introduced and systematically measure the parameters, we pick sketched variables randomly (inequalities and arithmetic) and use the same examples from our dataset (randomly picking the correct amount) for all models.

In Figure \ref{fig:systematic_solutions}, we observe that while there is a certain variation in the number of solutions, they demonstrate similar behavior. \skadded{For each encoding we have introduced $5$ sketched variables and measured the number of solutions and the model's precision. In Figure \ref{fig:systematic_precision} we see that there is indeed a slight variation in precision, with 3 out of 4 clearly reaching above 90\% precision, one reaching 100\% and one getting 82\%. Thus, despite variations in encoding, they generaly behave similarly on the key metrics. }  The results have been averaged over $100$ runs.


\begin{figure*}[tb]
  \centering
 \begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\textwidth]{latin_square_generalization.png}
  \caption{\skadded{Measuring the generalized accuracy and number of solutions. Latin Square $4 \times 4$.}}
  \label{fig:latin_square_generalization}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\linewidth]{n_queens_all_models_number_of_solutions_manual.png}
  \caption{\skadded{The number of solutions (default preferences) for various $N$-queen encodings}}
  \label{fig:systematic_solutions}
  \end{subfigure}
\hfill
 \begin{subfigure}[t]{0.325\textwidth}
  \includegraphics[width=\scalefigures\textwidth]{quees_different_precision.png}
  \caption{\skadded{Correctness for $N$-queens various encodings (precision)}}
  \label{fig:systematic_precision}
\end{subfigure}
\caption{\skadded{\qfour and \qfive: generalization (left), effect of the encoding variations on \# solutions (middle), on precision (right)}}
\end{figure*}




Overall, we observe that only few examples are needed to converge to a unique or a small group of equivalent solutions. An example where such equivalent solutions are found is the \text{edge coloring problem}, where two equivalent (for undirected graphs) constraints are found:
\begin{equation*}
  \begin{aligned}
 &\leftarrow \textit{color}(X,Y_1,C), \textit{color}(X,Y_2,C),~Y_1 \neq Y_2.\\
 &\leftarrow \textit{color}(X_1,Y,C), \textit{color}(X_2,Y,C),~X_1 \neq X_2.
  \end{aligned}
\end{equation*}
For this problem these two constraints are equivalent and cannot be differentiated by any valid example. %In the experiments we have only two such cases: the one described above and $n$-queens with three symmetric solutions under the default preferences.



An interesting observation we made on these experiments is that the 
hardness (e.g., in terms of runtime) of searching for a solution of 
a problem is not directly connected to the hardness of learning the 
constraints of this problem. This can be explained by the incomparability of the search spaces. 
The SkASP searches through the search space of sketched variables, 
which is usually much smaller than  the search space of the set of decision variables 
of the problem to learn.

\section{Related Work}\label{sec:related_work}
The problem of sketched ASP is related to a number of topics.
First, the idea of sketching originates from the area of programming languages, where
it relates to so called self-completing programs \parencite{sketching_phd_thesis}, typically in C \parencite{sketching_original} and in Java \parencite{jsketch}, where an imperative program has a question mark instead of a constant and a programmer provides a number of examples to find the right substitution for it. While sketching has been used in imperative programming languages, it has -- to the best of the authors' knowledge -- never been applied to ASP and constraint programming.  What is also new is that the sketched ASP is solved using a standard ASP solver, i.e., ASP itself.

Second, there is a connection to the field of inductive (logic) programming (ILP)  \parencite{ilp_book,ilp_original,gulwani2015inductive}
as one induces programs from examples of their intended behaviour.  
An example of such approach is the work on meta-interpretive learning \parencite{MuggletonMLJ14,MuggletonMLJ15} where 
a Prolog program is learned from a set of higher-order rules and examples. The higher-order rule acts as a kind of template
that can be used to complete the program. 
However, meta-interpretive learning differs from SkASP in that it induces full programs 
and pursues as other ILP methods a search- and trace-based approach guided by generality, 
whereas SkASP using a constraint solver (i.e., ASP itself) directly.  Furthermore, the target is different in that ASPs are learned, which include constraints. %rather than Prolog or Datalog programs. % On the other hand, meta-interpretive learning also supports predicate invention. 
There is also a connection to meta-interpretation in ASP \parencite{asp_meta}, such as rule and decision materialization. The purpose of is, however, different: they aim at synthesizing a program of higher complexity ($\Sigma_2^P$) given programs of lower complexity (\textit{NP} and \textit{Co-NP}).

There are also interesting works in the intersection of ILP, program synthesis and ASP \skadded{\parencite{inductive_asp,inductive_asp2}. The ILASP system \parencite{ILASP_system} learns an ASP program from  examples, and a set of modes, while minimizing a metric, typically the number of atoms. While there are similarities in the definitions and used ASP meta-programming techniques,} the program, learned completely from scratch, is not necessarily the best program from the user's point of view and may limit the possibility to localize the uncertainty based on the user's knowledge of the problem.  \skadded{Indeed, if all sketched predicates are added in the modes with corresponding background knowledge, then the set of hypotheses of sketched ASP is a subset of ILASP. However, if we specify a sketched constraint \texttt{:- p(X),q(Y),X?=Y} with the negative example \texttt{\{p(1),q(2)\}} as modes for ILASP \parencite{ILASP_system}, ILASP would learn a program like \texttt{:- p(X)}, since that is a minimal program in the number of atoms but that is clearly not the program intended by the sketch. Furthermore, we aim at computing the set of preferred programs instead of a single solution. %(For a more detailed comparison, we refer to the supplementary material.) %From the Blumer bound \parencite{Blumer_bound} we know that the PAC bound on the hypothesis error logarithmically depends on the hypothesis size, which gives better generalization error to sketching.
  SkASP is also related to XHAIL \parencite{xhail} an ILP abduction system, which, however, does not support constraints that are at the core of our system. }

Third, there is also work on constraint learning, where the systems such as CONACQ \parencite{original_constraint_learning,besetalAIJ17} and QUACQ \parencite{QUACQ} learn a set of propositional constraints,  and ModelSeeker \parencite{BeldiceanuS12} learns global constraints governing a particular set of examples.  The subject has also been investigated in ILP setting \parencite{lallouet}. 
However, the idea in all these approaches is to learn the complete specification of CSPs from scratch. Our setting is probably more realistic 
from a user perspective as it allows to use the knowledge that the user no doubt possesses about the underlying problem,
and also requires much less examples.  On the other hand, SkASP also makes, as other sketching approaches,
the strong assumption that the intended target program is an instance of the sketched one. This may not always
be true, for instance, when rules are missing in the program.  This is an interesting issue for further research.

Fourth, our approach is related to debugging of ASP \parencite{debugging_using_meta_asp,debugging_asp}. 
Unlike SkASP such debuggers can be used to locate bugs, but typically 
do not provide help in fixing them. On the other hand,
once a bug is identified, SkASP could be used to repair it by introducing a sketch and a number of examples. \footnote{ {\scriptsize During the experiments, we stumbled upon a peculiar bug. One encoding worked mostly by pure luck. The following constraint \texttt{:-queen(X1,Y1),queen(X2,Y2),X1<X2,abs(Y1-X1)==abs(Y2-X2).} works because \texttt{abs} is not actually absolute value but an 
uninterpreted function, essentially it checks $X == Y$, and that is indeed the found solution. \skadded{(This kind of bugs would be extremely hard to find using traditional debuggers, since technically the encoding produced correct solutions.)} 
Also, while working on the aggregate extension use-case, we discovered a subtle bug: the case of a single celebrity was not handled correctly. In both cases, the author has been contacted and models have been updated.}} The approach of \parencite{ilp_debugging_asp} is based on classical ILP techniques of generalization and specification and does not provide the freedom to indicate uncertain parts of the program.



% \section{Practical Applications: Query Sketching} \label{sec:applications}
% \skadded{There is an important area of research in databases, called query-by-example (QBE) \parencite{query_by_example}, where one recovers a query, given a database and positive and negative output tuples. Typically, QBE algorithms have two parts: query-optimization and search. The former is to reduce the search space and the latter is to look for a query. The technique described in this paper, enhanced with the query-optimization methods from QBE would allow to model the search component and port the sketching idea into the database setting, \textit{Query Sketching}.}

% \skadded{E.g., consider a standard database setting with an employee database, where a user needs to select all highly-paid employees not from sales departments. The user knows the general structure of the query, i.e. a join between two tables with a filtering condition on columns, but she is unsure of the exact combination of values. Thus, she leaves all the comparisons with constants open.}


% \begin{minipage}{0.41\linewidth}
%   SQL representation 
% \begin{minted}[fontsize=\scriptsize]{sql}
% SELECT Fname, Lname
% FROM Emp as e,Dept as d
% WHERE e.d_id = d.id
% AND e.pos         = ?c1
% AND e.salary      > ?c2
% AND d.dept_funct != ?c3 
% \end{minted}
% \end{minipage}
% \hfill
% \begin{minipage}{0.52\linewidth}
%   Datalog representation
% \begin{Verbatim}[fontsize=\scriptsize,xleftmargin=0mm,commandchars=\\\{\}]
% q(Fname,Lname) :- 
%  emp(Id,D,Fname,Lname,Pos,Sal),
%  dept(D,Dname,Funct,Manager),
%  Pos    = ?c1, 
%  Sal    > ?c2,
%  Funct != ?c3.
% \end{Verbatim}
% \end{minipage}





\section{Discussion and Conclusions}\label{sec:discussion}
Our contribution is four-fold: we have introduced the problem of sketched ASP; we have provided a rewriting schema for SkASP; we showed that the complexity of the rewriting is the same as that of the existence of an AS; we have created a dataset of sketches and evaluated our approach empirically demonstrating its efficiency and effectiveness.

User interaction is an interesting direction for future work, namely to suggest constraints and examples. For the former, if we are not able to reject a negative example, we can construct a constraint that would reject the negative examples and none of the positive examples. As for the examples, if we have two solutions to a problem, we can generate an example discriminating between them and ask user to clarify it, while this might not always be possible, since symmetric assignments might lead to semantically identical programs. In practice, however, this might be an important addition to simplify sketching for end users. Another interesting direction is to incorporate \skadded{non-constant} preference handling  into the ASP model using the extensions of ASP for preference handling, such as \textit{asprin} \parencite{asprin}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage


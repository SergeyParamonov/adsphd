\chapter{Conclusions and future work}\label{ch:conclusions}
\begin{addmargin}[2em]{2em}
This chapter summarizes the thesis and discusses open problems and
future work opportunities.
\end{addmargin}

\section{Summary and conclusions}
Purely declarative machine learning and data mining, the holy grail of
data analysis, is yet a long way ahead of us but today we
have made a step.

First, we have introduced two types of data used in data mining:
propositional and relational data. We have contrasted their
differences and their use in various problems. Namely, we have
indicated that propositional data is common for predictive models (that
we do not investigate in this thesis), while relational data is common
for problems like constraint learning or pattern mining. We have also
demonstrated how the Boolean Factorization problem can be generalized
to Relational Data Factorization, once we consider relational data.
As we have demonstrated these problems can be clearly seen as
relational data mining problems and require first order languages for
modelling.

More specifically, we have showed that the problems such as tabular
constraint learning are relational in its nature due to the data used
in it and due to the constraints connecting multiple tables and
breaking single-tuple single-table representation, when rows and
columns are no longer independent.

To solve these relational problems we have used a declarative approach,
where one specifies what the problem is and not how to solve it. For
the problems we have described this declarative approach is natural, since many
data mining problems are combinatorial search problems, i.e., they
can be phrased in terms of ''Model + Search``. To solve these relational
models under a variety of constraints, we used general solvers based
on constraint and logic programing such as Answer Set Programming and
FO(.) IDP. Since logic is designed to work with relations and both ASP
and IDP support first order statements, they both allow for a natural
representation of relational data mining models and data associated
with them. The experimental evidence, presented here,
shows the efficiency of
these systems in solving relational data mining problems.

Furthermore, as we have seen, relational data is so widespread that it is
impossible to ignore. This implies that relational mining problems
would affect many industries, where for example, spreadsheets are
an essential part of business processes, as in finance or auditing.
This gives us confidence not only in that relational problems are a
crucial part of data mining but also in that we should investigate
applications of general solvers, such as ASP and IDP, for data mining
and machine learning. In fact, it provides the solver developer community
with important benchmarks and problems to improve solvers. The inverse
process is also happening, once solvers get better, new types of problems
can be tackled.

\section{Contributions and key questions}
In the introduction chapter we have identified the key research
question and key problems we were going to apply our approach to. Now
we are going to review these applications and to analyze the outcome.

\begin{description}
\item[\cone] \textit{\textbf{Relational Data Factorization.} What are the challenges and advantages of generalizing classic data mining problems, such as the Boolean Matrix
    Factorization problem, into the relation setting?}
\end{description}

As we see in Chapter \ref{ch:ReDF}, the key advantage is the
generality and flexibility of the approach, however, it often comes at
the cost of longer runtimes of the method. There are a number of ways
as has been indicated to handle this problem but it should not come as
a surprise that general methods cannot compete the out-of-the-box in
terms of the efficiency with
a specialized method devoted to only one particular problem. It is
also clear that specialized methods must be significantly modified in
order to be used in a new setting. Our extensive experimental study
also demonstrates that general relational methods are well-suited for
system prototyping.

Namely, we have demonstrated that not only tiling and Boolean matrix
factorization can be solved declaratively using ASP, but also
factorizations with multiple tables under constraints, which allowed
us to visualize relational groups of co-authors of a
number of known data mining researchers. Finally, this showed that a
broad variety of mining problems can be modelled using relational
factorization and solved using modern logic programming
techniques.

\begin{description}
    \item[\ctwo] \textit{\textbf{Tabular Constraint Learning.} How can the constraint learning problem be formulated
   and modelled in the relational setting, where data is
   represented as spreadsheets, i.e., connected relations, and constraints are
   tabular Excel-like formulae?
}
\end{description}

As has been shown in Chapter \ref{ch:TaCLe}, the problems related to
spreadsheet data are intrinsically relational, since the data itself
consists of multiple relations together with the dependencies between
them. We have introduced the system called \acrlong{tacle}, based on
classic \acrshort{ilp} ideas, to work in this setting. The systems
enumerates the Excel-like constraints by working on them in the same
manner as clause-learning systems do. It is able to detect the most
popular Excel functions in spreadsheet data within a table as
well as between multiple tables. This indicates \acrlong{tacle}'s
applicability in practice, potentially, it can be turned into a plugin
for Excel or Google Spreadsheets,
which can help a broad audience of users.

Furthermore, we have introduced the first tabular constraint dataset
and provided an experimental evidence on the efficiency of the TaCLe
algorithm. Also, we have studied limitations of the method
such as sensitivity to noise, nested constraints and richer type
systems. As a result, we have proposed a modification of the existing
system, a second generation TaCLe system, that would potentially
overcome these issues.

\begin{description}
    \item[\cthree] \textit{\textbf{ASP Sketching.} How can the problem of ASP
      Sketching, where one marks certain parts of the
        program to be uncertain, be modelled and solved using our
        declarative approach? 
}
\end{description}

As we have demonstrated in Chapter \ref{ch:sketching}, given a
partially complete specification of an ASP program, \acrshort{asp}
can successfully learn relational programs based on a few examples
provided. We have extensively analyzed the learned programs and
discovered that on average only few, typically between 2-5, examples
are needed to
converge to a correct solution. Furthermore, we were able to detect
errors in publicly available encodings, we have contacted the authors
and the models were updated.

The general rewriting schema we have proposed is general and not
limited to the ASP used in the chapter for solving. The same algorithm
    and schema can be applied to Constraint Programming or FO(.) IDP.
    In fact, this schema also allows for developing some other practical
    applications such as spreadsheet formula sketching.


\begin{description}
    \item[\cfour]  \textit{ \textbf{ASP-based Relational Pattern Mining.}
    How can we apply declarative relational mining techniques, such as
        logic programming, to relational pattern mining, such as sequence, graph and query mining?
}
\end{description}

As indicated in Chapter \ref{ch:StructuredMining}, we have applied 
logic programming methods to the structured mining problems. As the
result, 
a purely declarative model of graph mining has been created. What we
have discovered is that the systems cannot yet handle this type of
models efficiently. Then, to overcome this issue, we have proposed a hybrid model that
first applies a standard pattern mining algorithm and then uses a
logic programming engine. This has lead to an order of magnitude
efficiency jump and, from the practical point of view, it seems to be
a ruitful direction of future research in declarative pattern
mining.

\section{Discussion and future work}
Let us introduce possibilities of future work here. Each chapter
describes the future work specific for a particular area or a problem,
while in this chapter we describe possible future directions from the
perspective of the thesis as a whole.


\paragraph{Relational data mining in future years}
As indicated in Chapter \ref{ch:StructuredMining}, hybridization of
declarative models is a promising and fruitful research direction. It
allows one to combine highly efficient specialized algorithms with
general solvers to create, on the one hand, efficient and scalable
systems; and on the other hand, general systems that can handle not
only particular restricted problems but suitable for the whole class of pattern
mining problems. Similar to the dominance programming for itemset
mining \parencite{dominanceprogramming} and our hybridization approach
to structured pattern mining \parencite{ruleml_hybrid}, we can foresee
a creation of 
general mining languages that handle various types of data and
multiple types of condensed representations, while demonstrating close to
state-of-art performance. These languages would allow a user to
specify all needed building blocks to generate an executable model
that can find all condensed patterns within reasonable time.

On the relational learning side, inspired by the results of TaCLe
\parencite{tacle} in Chapter \ref{ch:TaCLe} and Flashfill \parencite{flashfill}, we envision an intelligent
assistant that can help the user by analyzing tabular data in a
spreadsheet and suggest possible cleaning transformations, usage of
Excel-like formulae and data compression. The later idea of data
compression, which can be seen as a form of cleaning, connects to the
ideas of Relational Factorization in Chapter \ref{ch:ReDF}.
Similarly, as we can think of \textit{Spreadsheet Formula Sketching}, where the assistant can allow the user to specify some of the
formulae or constraints, while leaving certain parts open. Then, the
system can infer possible substitutions from the given tabular data.

Furthermore, the development of applications would drive  the
development of the solvers as well. We can imagine the support of
sketching techniques from Chapter \ref{ch:sketching} being implemented
on the solver level directly. Richer constraint languages might come
into the learning process, when a model satisfies a negative example
and the system might suggest a new constraint that the model is
missing or find the largest set of constraints consistent with the
examples.

Finally, we can imagine a fully automated tool able to analyze and
clean data in a standard format, such as a spreadsheet. Such a system
can work in the unsupervised setting and would not require  user interaction
or only to check if a suggestion looks ok, or which transformation looks better.
We regards a creation of such a tool as a long term research direction for
the future developments of the ideas, tools and models, presented in
this thesis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}

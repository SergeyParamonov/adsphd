%\subsection{Relational Data Factorization Example}\label{subsection:exampl}

Before we formalize the ReDF problem and approach in its full generality, we illustrate Relational Data Factorization on the \textit{sells(Company, Part, Project)} example from the Introduction.

\subsection{An example}

Assume we are given 1) a set of tuples for the {\em database} relation \textit{sells(Company, Part, Project)},
2) a definite {\em shape} clause defining the predicate $\appr\textit{(Company,}$ $\textit{Part, Project)}$, e.g.,
\begin{align*}
 \textit{\appr(Com, Pa, Proj)} \leftarrow \textit{offers(Com, Pa), needs(Proj, Pa), deliversto(Com, Proj),}
\end{align*}
 which should approximate the database relation \textit{sells(Company, Part, Project)} in
 terms of the (unknown) relations \textit{offers(Company, Part)}, \textit{needs(Project, Part)} and \textit{deliversto(Com, Project)},
 and
3)   an   \error function $\error(\appr, \textit{sells})$ that measures how 
different the database predicate 
and its approximation are, e.g., the number of tuples that is one in relation but not in the other. 
Then, the goal is to find sets of tuples for the unknown relations that minimize the \error. 

In practice, it is usually impossible to find a perfect solution (with $\error=0$) to relational data factorization problems, in this example because of Heath's theorem \parencite{heath_theorem} (as discussed in the Introduction). Therefore, it is often useful to impose further restrictions on the sets to be considered. One such constraint could specify that there is no {\em overcoverage}, i.e., that all tuples in \appr must be in \textit{sells}.

\subsection{Problem statement}

Using a logic programming formalism, we generalize the above example into the following ReDF problem statement.\\
\textbf{Given:}
\begin{itemize}
  \item a dataset $D$: a set of ground facts for target predicate \db;
  \item a factorization shape $Q$: $\appr(\bar T) \leftarrow q_1(\bar T_1), \dots, q_k(\bar T_k)$, where the $q_i$ are factors and the $\bar T_i$ denote tuples of variables;
  \item a set of constraints $C$;
  \item an \error function measuring difference between two predicates (i.e., between the corresponding sets of ground facts); 
\end{itemize}
\textbf{Find}: the set of ground facts $F$ for the factors $q_i$ that minimizes $\error(\appr,\db)$ and for which $Q \cup F \cup D$ satisfies
all constraints in $C$.% here $Q(F)$ denotes the set of all ground facts for
\\ 
\\
The factorization shape is a single non-recursive rule defining \appr, the 
approximation of the target predicate $\db$, where the predicates in the body are the factors. If a variable occurs in a body atom $\bar T_i$ and not in $\bar T$ (the head), then it is called \textit{latent}. The task is to find a set $F$ of ground facts defining the factors $q_i$. Furthermore, each such set $F$ uniquely determines a set of facts for \appr. 
Notice that if a predicate $q_i$ is already known and defined, then the task simplifies. 

As in matrix factorization, it is quite likely that a perfect solution, with $\error=0$, cannot be obtained. %($Q(F) = D$). 
Consider the following example: $\db(X,Y) \leftarrow p(X), q(Y)$ and dataset $D = \{ \db(a,c), \db(b,d)\}$.
Then it is impossible to perfectly reconstruct the target $D$. If $F = \{p(a), p(b), q(c), q(d)\}$, the resulting program overgeneralizes as it entails facts not in $D$:  $\db(a,d) \in \appr$ and $\db(a,d) \not\in D$; if, on the other hand, there are facts in $D$ that are not entailed in $\appr$, one undergeneralizes (e.g., when $F = \emptyset$). 

The scoring function in relational factorization measures the \error between the 
predicates \appr and \db. Instead of minimizing \error, however, in some cases it is more convenient
to maximize {\em similarity}. Since these two perspectives can be trivially transformed from one to the other, we will use both without loss of generality. 

\subsection{Approach}
To make this setup operational, we represent ReDF problems at two different levels. First, at the high level, we characterize typical constraints of interest that are employed across different models. Further, all problems are formulated using the template shown in Listing~\ref{lst:template:encoding}. Second, at the low level, the high-level constraints and encodings are formulated in ASP. The high-level constraints can in principle be automatically transformed into low-level ones.

\begin{lstlisting}[style=model,caption=Prototypical template of a high level problem encoding, label=lst:template:encoding]
 @\textbf{Input:}@ a set of facts $D$ for the $\db$ predicate 
 @\textbf{Shape:}@  $\appr(\bar T) \leftarrow q_1(\bar T_1), \dots, q_k(\bar T_k)$
 @\textbf{Find:}@  $q_1 \ldots q_k$
 @\textbf{Satisfying:}@  @$C_1(\appr,\db) \wedge \ldots \wedge C_n(\appr,\db)$@
 @\textbf{Minimizing:}@  @$\error(\appr,\db)$@\end{lstlisting}
%\vspace{5pt}

We next illustrate this on the {\em sells} example. The high-level description from which we start is given in Listing~\ref{lst:sells:encoding}.

\begin{lstlisting}[style=model,caption=Sells example encoding, label=lst:sells:encoding]
@\textbf{Input:}@ $\textit{sells(c1,pa1,proj1), sells(c2,pa1,proj2)}$ 
@\textbf{Shape:}@  $\appr(C,\textit{Pa},\textit{Prj}) \leftarrow \textit{offers(C,Pa), needs(Prj,Pa), deliversto(C,Prj).}$
@\textbf{Find:}@  @\textit{offers($\cdot$), needs($\cdot$), deliversto($\cdot$)}@
@\textbf{Minimizing:}@  @$\error(\appr,\textit{sells})$@
\end{lstlisting}

Next, this high-level formulation can be encoded in and solved using the ASP program given in Listing~\ref{lst:sells} (here, an ASP program can be thought as a conjunction of logical rules, where implication is denoted by ``:-'').

\lstset{numbers=left,
  keepspaces=true,
  numberstyle=\tiny,
  numbersep=5pt,
  basicstyle=\small,
  stringstyle=\sffamily,
  columns=fullflexible,
  flexiblecolumns=true,
  belowskip=5pt,
  alsoletter={-}, 
  alsodigit={:},
%  otherkeywords={},
  emph={%
      not,
      :-,
          },emphstyle={\bfseries}%
}

\begin{lstlisting}[caption=Factorization of a ternary relation into three binary relations, escapeinside={@}{@}, label=lst:sells,mathescape] 
@\commenttextasp{\%factorization shape}@
approx(Com,Pa,Proj) :- offers(Com,Pa), needs(Proj,Pa), deliversto(Com,Proj). @\label{lst:sells:1}@
@\commenttextasp{\%relation generators}@
0 { offers(Com,Pa)          } 1 :- sells(Com,Pa,Proj). @\label{lst:sells:gen1}@
0 { needs(Proj,Pa)           } 1 :- sells(Com,Pa,Proj). @\label{lst:sells:gen2}@
0 { deliversto(Com,Proj) } 1 :- sells(Com,Pa,Proj). @\label{lst:sells:gen3}@
@\commenttextasp{\%optimization function}@
overcoverage(Com,Pa,Proj)   :-        approx(Com,Pa,Proj), not sells(Com,Pa,Proj). @\label{lst:sells:incorrect1}@
undercoverage(Com,Pa,Proj) :- not approx(Com,Pa,Proj),        sells(Com,Pa,Proj). @\label{lst:sells:incorrect2}@
error(Com,Pa,Proj) :- undercoverage(Com,Pa,Proj). @\label{lst:sells:e1}@
error(Com,Pa,Proj) :- overcoverage(Com,Pa,Proj). @\label{lst:selss:e2}@
@\#@minimize[error(Com,Pa,Proj)]. @\label{lst:sells:minimize}@
\end{lstlisting}

%The ReDF framework relies on ASP for modeling and solving this type of problem. 
We introduce ASP in more detail below, but this model is easy to understand if one is familiar with the basics of logic programming. The ASP model basically defines the necessary predicates in ASP using a set of clauses. In addition, the rule in Line \ref{lst:sells:gen1} encodes the constraint that whenever a tuple holds for \textit{sells(Com, Pa, Proj)}
there should be 0 or 1 corresponding tuples for the predicate \textit{offers(Com, Pa).}
Furthermore, the minimize statement specifies that we are looking for a model (a set of ground facts or tuples) that minimizes the error.  The encoding in Listing  \ref{lst:sells} together with a set of facts for \textit{sells}
can be given to an ASP solver such as clasp \parencite{gebser2011potassco}. % which can then be used to generate an answer set (a model)
%that includes the definitions of the factors.  


Observe that the relational data factorization approach we propose perfectly fits within the declarative modeling paradigm for machine learning and data mining \parencite{DeRaedtECML12}.  Indeed, the next sections will show that it naturally supports a wide range of popular and well-known factorization problems. 
Modeling different problems corresponds to specifying different constraints, shapes and optimization functions.
By doing so, one obtains a deep understanding of the relationships among the many variations of factorization, 
and one can easily design, prototype and experiment with new variations of factorization problems. 
Furthermore, the models of factorization are in principle solver-independent and do not depend on a particular ASP solver implementation.   

Notice that it would also be possible to use other constraint satisfaction and optimization approaches
(such as, e.g., Integer Linear Programming), but given that we work within a relational framework, ASP is a natural choice. It is also declarative and has the right expressiveness for the class of problems that we will study, many of which are NP-complete such as BMF; see Subsection \ref{subsection:bmf}. 

Finally, let us mention that there are many factorization approaches in both linear algebra, databases, and even in logic. We provide a detailed discussion of their relationship to ReDF in Section \ref{sec:relwork}.

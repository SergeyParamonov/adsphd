\chapter{Introduction}\label{ch:introduction}
\epigraph{
- Homer, is it the way you pictured PhD life?\\
- Yeah, pretty much, except we drove in a van solving mysteries.
}{Could be Homer Simpson}

\begin{addmargin}[2em]{2em}
This thesis links the research fields of data mining, constraint learning
and logic programming. We introduce them in turn and provide an overview of the
contributions of the thesis and
its general structure.
\end{addmargin}

The ability to write down a model and just push a button to get the
answer is an appealing idea. It is one of the holy grails of
Artificial Intelligence, called Declarative Programming. Today in the age of data, we would like
to write models, feed them with data and find the insight slipping
away from a human eye. What we do not really want to do is to write
all of tedious code. Once, we have written a model, we would like just
to a feature to it and get an updated answer. Unsurprisingly, it is
not an easy task. To tackle it we need first to introduce Data Mining
problems and then attack them with the most powerful weapon -- Logic.
The main reason behind this is simple: in this thesis, we are
concerned with Relational Data and Relational Data Mining Problems.
And Logic is the best modelling tool to handle relational data
problems.

\section{Data Mining}
Data Mining is the scientific area concerned with turning data into
knowledge. The amount of data available and generated today is simply
enormous and Data Mining is
devoted to structuring, filtering, classifying and extracting useful
patterns from this data.

The \textit{knowledge} extracted from the data can manifest itself in
multiple forms. For example, an interesting piece of a data,
\textit{typically a substructure}, can be
referred as a \textit{pattern} \parencite{han_book}. The most known is
\textit{frequent pattern mining} \parencite{survey_han}. In fact, various measures of
``interest'' exist, which has given a raise to multiple types of
patterns to look for \parencite{tias_topk}.


Many Data Mining problems, and especially \textit{Pattern Mining
problems}, are \textbf{combinatorial problems}, which
is 

\begin{center}
  Combinatorial problem = Model + Search
\end{center}

Therefore, it seems natural to model them using systems designed to
perform search in declarative manner, such as \acrlong{cp} or
\acrlong{asp} (which we discuss later in detail).

If we simplify the details, then a pattern mining problem can be
viewed as follows: let $D$ be a set of object and $\phi$ be a function of
interest, then find all objects $d$ in $D$ such that $\phi(d)$ holds.
Simply speaking, we enumerate objects that have a certain property of
interest.


\section{Constraint Learning}
Constraint Learning is the research field concerned with finding
constraints in the data \parencite{constraint_learning,QUACQ,Conacq}.
Let us outline in simple terms, what constraint learning is about.
Explaining what constraint learning in term of the previous section:
let $D$ be a dataset and $\Phi$ be a set of interesting properties:
then find all properties $\phi$ in $\Phi$ such that $\phi(D)$ holds.

It is not hard to see a certain duality between these problems, essentially:
\begin{center}
  \textbf{Patterns are constraints and constraints are patterns}.
\end{center}

In case of pattern mining, we enumerate objects on which the property
of interest holds and in constraint learning we find interesting
properties that hold in the data (or its parts).

Therefore, constraint learning and pattern mining are interconnected
and both play a central role in this thesis.

\section{Logic Programming}
In his seminal work Sir Bob \textcite{kowalski} proclaimed:
\begin{center}
  Algorithm = Logic + Control.
\end{center}

What he meant is quite simple, you can turn logical rules into a
computational process. Why is this important for us? Logic deals with
relations and relational structures, it is naturally designed to be
working in the relational setting. Therefore, if we can combine logic
with computations we obtain a computational engine that can work in
our relational learning setting.


Imagine, that there are three people: John, Peter and Elena. We know
that people who are not allergic to fish like sushi; and Peter is
allergic to fish. Who likes sushi then? We can write this puzzle as a
simple logical implication:

\begin{equation*}
  \textit{likes\_sushi}(X)~{:}{-}~\textit{person}(X),~\text{not}~
  \textit{allergic}(X). 
\end{equation*}

This notation of Prolog (Programming in logic) mimics the logical implication:

\begin{equation*}
  \forall X: \textit{person}(X), \overline{\textit{allergic}}(X)
  \implies \textit{likes\_sushi}(X)
\end{equation*}

Indeed, in this thesis we use modern Logic Programming engines: such
as \acrlong{asp} \cite{ASPbook,whatisasp} and \acrlong{idp}
\parencite{idp} (we explain them in details in the following chapter)
that naturally support constraints and various types of logical
inference.


\section{Contribution}
Given the abundance of relational data (such as spreadsheets, graphs
or logical structures) and of various machine learning and data
problems. A natural question arises: \textit{``How can we model
relational data mining problems?''}. This thesis introduces a number
of foundational relational problems and offers a uniform view on them.
Since the data and problems are relational, we approach them using
relational methods, namely, logic programming.

The \textbf{main contribution} of this thesis is in the novel problems
it offers.

Conretely, the thesis investigates the following questions:
\begin{itemize}
  \item \cone: What are the challenges and advantages of generalizing
    classic data mining problems, such as the Boolean Matrix
    Factorization problem, into the relation setting?
  \item \ctwo: What practical problems are intrinsically relational and
    how can they be modelled and used in practice?
  \item \cthree: Looking at the inversed problem: given a relational
    model, can we mark some parts of its to be uncertain and in what
    setting would it be applicable?
  \item \cfour: Similarly to unstructured constraint-based itemset
    mining: can we apply declarative relational mining
    techniques to structured patter mining, such as sequence, graph
    and query mining?
\end{itemize}

Addressing \cone, we look into a classical problem of matrix
factorization. We demonstrate how the problem of Boolean Matrix
Factorization can be generalized into relational setting, called
\textit{Relational Data Factorization}, and
demonstrate how it allows to model a variaty of classic data mining
problems and novel tasks as well.

With the regard to \ctwo: we look into a more practical setting.
Typically, machine learning and data mining algorithms make the i.i.d.
(independent identically distributed) assumption, which, of course,
breaks in the relational setting. If we look at a spreadsheet, it is
typically one or more tables with relationaships between them. Usually
in a form of a formula, a macro or of some other constraint. If we
want to detect these connections between tables or their parts, we
have to give up the i.i.d. assumption. This setting, referred as
\textit{Tabular constraint learning}, breaks the standard
machine learning and data mining algorithms and 
makes the problem essentially relational.

This leads us to \cthree: if we already have a relational model but
something changes over time or due to changes in the specification, then we would like
to be able to indicate uncertainty in some parts of the model. These
uncertain or, \textit{open}, parts are called \textit{sketched} and
the whole sketched model is referred as a \textit{sketch} and the
problem as \textit{constraint sketching}.

Finally, looking at \cfour: if we look at the area of itemset mining, where \acrlong{cp}
has been succefully applied, then the next natural question to ask:
if \acrshort{cp} has been succesful for unstructured, or
non-relational, pattern mining, can we model its \textit{structured},
or \textit{relational}, version using logic programming? To answer
this question we look into \textit{sequence}, \textit{graph} and
\textit{query mining} and attack them using logic programming and
hybrid approaches based on logic programming.


\section{Structure of the Thesis}
\textbf{Chapter} \ref{ch:background} introduces background information on Logic, Logic and Answer Set Programming and Pattern Mining.

\textbf{Chapter} \ref{ch:ReDF} presents the novel problem of Relational Data
Factorization. It demonstrates how this problem generalizes various
data mining problems such as Database Tiling and Boolean Matrix
Factorization. We start with the most basic setting and demonstrate
how various problems can be modelled within the framework by adding
or modifying the constraints. Then, we show how the framework can be
used for new and interesting applications and propose Answer Set
Programming as a method to solve the problem in the general case.
For each problem we provide an extensive experimental evidence,
including solver parameter tuning. The chapter consists of the
research previously published in the following paper:

\begin{addmargin}[2em]{2em}

Sergey Paramonov,  Matthijs van Leeuwen, Luc De Raedt: Relational data
factorization, Machine Learning, Springer, 2017

\end{addmargin}



\textbf{Chapter} \ref{ch:TaCLe} introduces  the novel problem of
Tabular Constraint Learning and the system, called TaCLe (pronounced
as the word ``tackle''). The problem setting is straightforward to
explain: we have an Excel file with formulae. The file is imported as
CSV. The formulae are lost. Can we reconstruct them? We can already 
see that the problem setting is different from the standard machine
learning problem. In a spreadsheet, columns are no longer variables
and rows are no longer records. Textual and numeric data are mixed.
Spreadsheet functions, like Fuzzy-lookup, are unorthodox and unseen in
the constraint programming and learning research communities.

The chapter consists of the research previously published in the following papers:

\begin{addmargin}[2em]{2em}
Samuel Kolb (*), Sergey Paramonov (*), Tias Guns, Luc De Raedt:
  Learning constraints in spreadsheets and tabular data. Machine
  Learning 106(9-10): 1441-1468 (2017)


Sergey Paramonov (*), Samuel Kolb (*), Tias Guns, Luc De Raedt:
TaCLe: Learning constraints in tabular data. CIKM. Sheridan
Communications, 2017.
\end{addmargin}


\textbf{Chapter} \ref{ch:Sketching} introduces the novel problem of
Sketched Answer Set Programming. The idea of sketching takes root in
imperative programming, when a function in C or Java has a part of it,
typically a constant left unspecified. A user then provides a number
of examples for this sketched constant to be filled in with a
correct value satisfying the examples. Inspired by this approach, we
introduce Sketched Answer Set Programming, where a user writes a
regular program but with certain parts such as constants, predicates
or operators are left uncertain. Then, we rewrite this sketched
program into a regular ASP program, i.e., we use a standard ASP solver
to complete sketches.


The chapter consists of the research previously published in the following papers:
\begin{addmargin}[2em]{2em}
  Sergey Paramonov, Christian Bessiere, Anton Dries, Luc De Raedt:
  Sketched Answer Set Programming. CoRR abs/1705.07429 (2017)
\end{addmargin}


\textbf{Chapter} \ref{ch:StructuredMining} introduces a logic
based approach to structured pattern mining. The idea to apply general
solvers to pattern mining takes root in the work of
\cite{declrativeapproach}, where Constraint Programming is applied to
Itemset Mining. Contrary to itemset mining, where objects do not have
any particular structures, structured mining studies mining patterns
in sequences, trees, graphs, etc. First, we introduce a general
mathematical model of graph mining based on the logical formulation of
the constraints. Second, we show that the model can be hybridized by
using our generic framework together with specialized solvers
developed for particular pattern mining problems.

The chapter consists of the research previously published in the following papers:
\begin{addmargin}[2em]{2em}
Sergey Paramonov, Matthijs van Leeuwen, Marc Denecker, Luc De Raedt:
An Exercise in Declarative Modeling for Relational Query Mining. ILP
2015: 166-182


Sergey Paramonov, Daria Stepanova, Pauli Miettinen:
Hybrid ASP-Based Approach to Pattern Mining. RuleML+RR 2017: 199-214


Tias Guns, Sergey Paramonov, Benjamin Ngrevergne:  On Declarative Modeling of Structured Pattern Mining. AAAI Workshop:
  Declarative Learning Based Programming 2016

Matthias van der Hallen, Sergey Paramonov, Gerda Janssens and
  Michael Leuschel:   Knowledge Representation Analysis of Graph
  Mining, ASPOCP 2016.

Sergey Paramonov, Tao Chen, Tias Guns: Generic Mining of Condensed
Pattern Representations under Constraints, YSIP, CEUR Workshop
Proceedings 1837, pp 168-177, 2017

\end{addmargin}

\textbf{Chapter} \ref{ch:conclusions} summarizes the thesis and
discusses future work possibilities.

\section{Datasets, Code and Experimental Results}
In order to make results repeatable and to follow the Open Source
spirit, we have opened and published the datasets, use-cases,
meta-data and other useful information.

They can be found in the following GitHub repositories:
\begin{itemize}
\item \url{https://github.com/SergeyParamonov/TaCLe}
\item \url{https://github.com/SergeyParamonov/sketching}
\item \url{https://github.com/SergeyParamonov/LGM}
\end{itemize}
\cleardoublepage
% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}

\chapter{Introduction}\label{ch:introduction}

In his seminal work Sir Bob \textcite{kowalski} proclaimed:
\begin{center}
  Algorithm = Logic + Control.
\end{center}




\section{Structure of the Thesis}
\textbf{Chapter} \ref{ch:background} introduces background information on Logic, Logic and Answer Set Programming and Pattern Mining.

\textbf{Chapter} \ref{ch:ReDF} presents the novel problem of Relational Data
Factorization. It demonstrates how this problem generalizes various
data mining problems such as Database Tiling and Boolean Matrix
Factorization. We start with the most basic setting and demonstrate
how various problems can be modelled within the framework by adding
or modifying the constraints. Then, we show how the framework can be
used for new and interesting applications and propose Answer Set
Programming as a method to solve the problem in the general case.
For each problem we provide an extensive experimental evidence,
including solver parameter tuning. The chapter consists of the
research previously published in the following paper:

\begin{addmargin}[2em]{2em}

Sergey Paramonov,  Matthijs van Leeuwen, Luc De Raedt: Relational data
factorization, Machine Learning, Springer, 2017

\end{addmargin}



\textbf{Chapter} \ref{ch:TaCLe} introduces  the novel problem of
Tabular Constraint Learning and the system, called TaCLe (pronounced
as the word ``tackle''). The problem setting is straightforward to
explain: we have an Excel file with formulae. The file is imported as
CSV. The formulae are lost. Can we reconstruct them? We can already 
see that the problem setting is different from the standard machine
learning problem. In a spreadsheet, columns are no longer variables
and rows are no longer records. Textual and numeric data are mixed.
Spreadsheet functions, like Fuzzy-lookup, are unorthodox and unseen in
the constraint programming and learning research communities.

The chapter consists of the research previously published in the following papers:

\begin{addmargin}[2em]{2em}
Samuel Kolb (*), Sergey Paramonov (*), Tias Guns, Luc De Raedt:
  Learning constraints in spreadsheets and tabular data. Machine
  Learning 106(9-10): 1441-1468 (2017)


Sergey Paramonov (*), Samuel Kolb (*), Tias Guns, Luc De Raedt:
TaCLe: Learning constraints in tabular data. CIKM. Sheridan
Communications, 2017.
\end{addmargin}


\textbf{Chapter} \ref{ch:Sketching} introduces the novel problem of
Sketched Answer Set Programming. The idea of sketching takes root in
imperative programming, when a function in C or Java has a part of it,
typically a constant left unspecified. A user then provides a number
of examples for the this sketched constant to be filled in with a
correct value satisfying the examples. \sergey{to be continued}

\section{Datasets, code and experimental results}

\sergey{talk about github here: TaCLe, SkASP, etc}

% Illustration on how to refer to your papers when using biblatex
% (see second line in thesis.tex to activate biblatex)
%\definecolor{shadecolor}{gray}{0.85}
%\begin{shaded}
%This chapter was previously published as:\\
%\fullcite{VandenBroeck2011IJCAI}
%\newpage
%\end{shaded}



%And yet another citation \cite{FrRo2010Diffusion}.

% Some dummy code to get at least 1 entry in the nomenclature.
%\nomenclature{$\Theta$}{A nice symbol}
%Introducing some symbol: $\Theta$.

% Some dummy code to get at least 1 entry in the list of
% abbreviations.

% Some dummy code show how to include images.
% \begin{figure}
%   \centering
%   \medskip
%   \includegraphics[width=.9\textwidth]{sine}
%   \caption{Illustration of how to include a figure. }
%   \label{fig:sine}
% \end{figure}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
